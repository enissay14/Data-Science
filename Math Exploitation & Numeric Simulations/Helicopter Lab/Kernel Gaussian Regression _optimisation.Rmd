---
title: "TP2"
author: "Landa & Delatte & Wang"
date: "January 13, 2016"
output: pdf_document
---
```{r}
library(DiceKriging)

y <- read.csv("mesures2.csv",header=F,sep=";")
y <- apply(y, 1, mean)

X <- read.csv2("X.304",header=T)
X <- subset(X, select= -1)
colnames(X) <- c("ww","wl","tl","alph")

summary(y)
plot(X[,1],y)
hist(as.matrix(y))
```
pour comparer les critères

```{r}
Q2 <- function(y, pred){
  1 - sum((y - pred)^2)/sum((y - mean(y))^2)
}
sdRMSE <- function(y, pred){
  sqrt(mean((y - pred)^2))/sd(y)
}
```
choix du noyau:
```{r}
#rendre en compte du bruit d'observation
epsilon <- 1e-3

m52 <- km(design=X, response=y,covtype="matern5_2",nugget=epsilon)
plot(m52)
lOO.m52 <- leaveOneOut.km(m52, type="UK", trend.reestim=FALSE)$mean

m32 <- km(design=X, response=y,covtype="matern3_2",nugget=epsilon)
plot(m32)
lOO.m32 <- leaveOneOut.km(m32, type="UK", trend.reestim=FALSE)$mean

mexp <- km(design=X, response=y,covtype="exp",nugget=epsilon)
plot(mexp)
lOO.mexp <- leaveOneOut.km(mexp, type="UK", trend.reestim=FALSE)$mean

mgauss <- km(design=X, response=y,covtype="gauss",nugget=epsilon)
plot(mgauss)
lOO.mgauss <- leaveOneOut.km(mgauss, type="UK", trend.reestim=FALSE)$mean

Q2(as.matrix(y),lOO.m52)
Q2(as.matrix(y),lOO.m32)
Q2(as.matrix(y),lOO.mexp) 
Q2(as.matrix(y),lOO.mgauss)

sdRMSE(as.matrix(y),lOO.m52)
sdRMSE(as.matrix(y),lOO.m32)
sdRMSE(as.matrix(y),lOO.mexp) 
sdRMSE(as.matrix(y),lOO.mgauss)
```
On garde le noyau matern 5/2, on check les intéractions qui influent le plus sur la tendance ensuite
```{r}

m <- km(design=X, response=y,covtype="matern5_2",nugget=epsilon)
lOO <- leaveOneOut.km(m, type="UK", trend.reestim=FALSE)$mean
m3 <- km(~.^3,design=X, response=y,covtype="matern5_2",nugget=epsilon)
lOO3 <- leaveOneOut.km(m3, type="UK", trend.reestim=FALSE)$mean
```
on garde les termes qui influent le plus

```{r}
m <- km(formula=~ ww*tl + ww*wl*tl + wl*tl*alph,design=X, response=y,covtype="matern5_2",nugget=epsilon)
lOO <- leaveOneOut.km(m, type="UK", trend.reestim=FALSE)$mean
Q2(as.matrix(y),lOO)
sdRMSE(as.matrix(y),lOO)

```


IMSE
```{r}
#pts of integration generation
steps <- 1000
x <- matrix(runif(steps*4,0,1) ,ncol = 4,nrow = steps) 
 

IMSE <- function(model, Xnew, integration.pts){
  Xnew <- matrix(xnew, ncol=4, byrow=TRUE)
  
  newmodel=km(formula=model@trend.formula, design=rbind(model@X, Xnew),
  response=c(model@y, rep(mean(model@y),nrow(Xnew))),
  covtype=model@covariance@name,coef.trend=model@trend.coef,
  coef.cov=covparam2vect(model@covariance),coef.var=model@covariance@sd2)
  
  I <- mean(predict(newmodel,integration.pts,type="UK",checkNames = F)$sd^2)
  I
}
xnew <- c(0.3,0.4,0.5,0.87,0.88,0.4,0.4,0.6,0.54,0.54,0.87,0.23)
IMSE(m,xnew,x)
```

choisir les nouveux points, on garde l'intervalle [0,1]
```{r}
install.packages("DiceEval_1.4.tar.gz", repos = NULL, type = "source")
install.packages("DiceView_1.3-1.tar.gz", repos = NULL, type = "source")
library("DiceView")
contourview(m,center=rep(0.5,4))
sectionview(m, center=rep(0.5,4))
sectionview3d(m, center=rep(0.5,4))

par( mfrow = c(1,1) )
plot(X[,1],y)
plot(X[,2],y)
plot(X[,3],y)
plot(X[,4],y)
```
CMA-ES
```{r}

cmaes <- function (test_fun, param){
  # User defined input parameters 
  xmean <- param$xinit     # initial point
  N <- length(xmean)       # problem dimension
  if (length(param$LB) == 1) 
    lower <- rep(param$LB, N)
  if (length(param$UB) == 1) 
    upper <- rep(param$UB, N)
  sigma <- param$sigma     # step size
  # Strategy parameter setting
  if (is.null(param$lambda)) {
    lambda <- 4 + floor(3 * log(N))        # default population size, offspring number 
  }
  if (is.null(param$mu)) {
    mu <- floor(lambda/2)                  # number of parents, points for recombination
  }
  maxiter <- ceiling( param$budget / lambda)
  weights <- log(mu + 1) - log(1:mu)     # recombination weights
  weights <- weights/sum(weights)        # normalize recombination weights
  mueff <- sum(weights)^2/sum(weights^2) # variance effective
  cc <- (4 + mueff/N) / (N + 4 + 2*mueff/N)  # cumulation for C control, approximation is 4/N   
  cs <- (mueff + 2)/(N + mueff + 5)      # cumulation for sigma control
  c1 <- 2 / ((N+1.3)^2+mueff)      # approximation is 2/N^2, learning rate for rank-one update of C
  cmu <- 2 * (mueff - 2 + 1/mueff) / ((N + 2)^2 + 2*mueff/2)  # approximation is 0.3*lambda/N^2    # learning rate for rank-mu update of C
  damps <-  1 + 2*max(0, sqrt((mueff - 1)/(N + 1)) - 1) + cs # damping for sigma 
  # Checking the algorithm initial parameters
  stopifnot(length(upper) == N)
  stopifnot(length(lower) == N)
  stopifnot(all(lower < upper))
  stopifnot(length(sigma) == 1)
  best.fit <- Inf
  best.par <- NULL
  sigma.log <- numeric(maxiter)
  eigen.log <- matrix(, maxiter, N)
  xmeanhist <- matrix(, maxiter,N)
  ymeanhist <- numeric(maxiter)
  
  if ( (is.null(param$autolog)) || (param$autolog==TRUE) ) {
    store_hist <<- TRUE # start history recording
    nbcalls <<- 0
    glob_xhist<<- matrix(, 1, ncol = N)
    glob_fhist<<- matrix(, 1, 1)
  }

  pc <- rep(0, N) ; ps <- rep(0, N)  # evolution paths for C and sigma
  B <- diag(N)       # matrix of eigenvectors of C
  D <- diag(N)       # diagonal matrix of eigenvalues of C
  BD <- B %*% D      
  C <- BD %*% t(BD)  # covariance matrix
  chiN <- sqrt(N) * (1 - 1/(4 * N) + 1/(21 * N^2))  # expectation of ||N(0, I)||
  iter <- 0L
  counteval <- 0L
  cviol <- 0L
  msg <- NULL
  arx <- matrix(0, nrow = N, ncol = lambda)
  arfitness <- numeric(lambda)
  while (iter < maxiter) {
    iter <- iter + 1L
    sigma.log[iter] <- sigma
    # Generate lambda offspring 
    arz <- matrix(rnorm(N * lambda), ncol = lambda) # matrix of size N*(lambda) contains standard normally distributed vectors
    arx <- xmean + sigma * (BD %*% arz)
    vx <- ifelse(arx > lower, ifelse(arx < upper, arx, upper), 
                 lower)               # enforce the sample points to be inside the bounds 
    pen <- 1 + colSums((arx - vx)^2)  # penalty of the offspring inside the bounds is 1, otherwise >1  
    pen[!is.finite(pen)] <- .Machine$double.xmax/2
    y <- apply(vx, 2, test_fun)
   
    counteval <- counteval + lambda
    arfitness <- y * pen

    arindex <- order(arfitness)
    arfitness <- arfitness[arindex]
    aripop <- arindex[1:mu]
    selx <- arx[, aripop]
    xmean <- drop(selx %*% weights)
    selz <- arz[, aripop]
    zmean <- drop(selz %*% weights)
    ymean <- drop(y[aripop] %*% weights)

    xmeanhist[iter,] <- xmean
    ymeanhist[iter] <- ymean
    # save the bests, 2 cases, noisy or not
    if (glob_noisy) {
      if (ymean < best.fit) {
        best.fit <- ymean
        best.par <- xmean
      }
    }
    else {
      valid <- pen <= 1
      if (any(valid)) {
        wb <- which.min(y[valid])
        if (y[valid][wb] < best.fit) {
          best.fit <- y[valid][wb]
          best.par <- arx[, valid, drop = FALSE][, wb]
        }
      }
    }


    norm <- function(x) drop(sqrt(crossprod(x)))
    ps <- (1 - cs) * ps + sqrt(cs * (2 - cs) * mueff) * (B %*% zmean)
    hsig <- drop((norm(ps)/sqrt(1 - (1 - cs)^(2 * counteval/lambda))/chiN) < (1.4 + 2/(N + 1)))
    pc <- (1 - cc) * pc + hsig * sqrt(cc * (2 - cc) * mueff) * drop(BD %*% zmean)
    BDz <- BD %*% selz
    # update of C
    C <- (1 - c1 -cmu) * C + c1 * (pc %o% pc + (1 - hsig) * cc * (2 - cc) * C) + cmu * BDz %*% diag(weights) %*% t(BDz)
    # Adapt step size sigma
    sigma <- sigma * exp((norm(ps)/chiN - 1) * cs/damps)
    e <- eigen(C, symmetric = TRUE)
    eigen.log[iter, ] <- rev(sort(e$values))
    if (!all(e$values >= sqrt(.Machine$double.eps) * abs(e$values[1]))) {
      msg <- "Covariance matrix 'C' is numerically not positive definite."
      break
    }
    B <- e$vectors
    D <- diag(sqrt(e$values), length(e$values))
    BD <- B %*% D
   }
  # add record and plot of sigma and eigenvalues
  res <- list(xhist=glob_xhist, fhist=glob_fhist, x_best=best.par, f_best=best.fit, sigmahist=sigma.log, xmeanhist=xmeanhist, ymeanhist=ymeanhist, eigenhist=eigen.log)

  if ( (is.null(param$autolog)) || (param$autolog==TRUE) ) {
    store_hist <<- FALSE  # end history recording
  }

  return(res)
}
IMSEwrapper <- function(xx){
  I <- IMSE(model = m,Xnew = xx, integration.pts = x)
  I
}

glob_noisy <- FALSE
param <- list(LB=0,UB = 1,budget = 50, dim=12, xinit=xnew,sigma=0.1)
b <- cmaes("IMSEwrapper",param) 

IMSE(m,xnew,x)
IMSE(m,b$x_best,x)

xbest <-  matrix(b$x_best, ncol=4, byrow=TRUE)
write()

```

